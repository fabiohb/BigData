set JAVA_HOME=c:\bigdata\java
set HADOOP_HOME=c:\bigdata\hadoop-3.1.1

hdfs namenode -format

..\sbin\start-yarn.cmd

pyspark









>>> a =[1,2,3,4]
>>> list(filter(lambda x: x < 3, a))


data = [('Ceara', 10), ('Bahia', 20), ('Pernambuco', 30)]
df = spark.createDataFrame(data, ('Estado', 'Qtd'))
df2 = spark.read.format('com.databricks.spark.csv').option('header','true').option('delimiter', '\t').option('inferSchema','True').load('/bigdata/dataset/201702_GastosDiretos-utf.csv')
df2=spark.read.format("com.databricks.spark.csv").option("header","true").option("delimiter", "\t").option("inferSchema","True").load('/bigdata/dataset/201702_GastosDiretos-utf.csv')



mongoimport -d bigdata -c gastos --type tsv --file c:\bigdata\dataset\201712_gastosDiretos_utf.csv --headerline 